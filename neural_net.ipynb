{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alphanumeric Image Classifier\n",
        "In this project, we learn how to create a simple Neural Network.\n",
        "\n",
        "The goal is to create a model capable of recognising an alphanumeric character (A-Z, a-z, 1-9).  \n",
        "The input will be a 32x24 pixel image. Any image we use will be downscaled to fit this size.\n",
        "\n",
        "#### What technologies did we use?\n",
        "We are not using Tensorflow or Pytorch.  \n",
        "We are only using simple functions and classes to represent perceptrons etc.\n",
        "\n",
        "Created by: andrewpublic & joshuao1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Q9h3tQ86KrMf"
      },
      "outputs": [],
      "source": [
        "# load data set\n",
        "\n",
        "# create training data sets\n",
        "\n",
        "# feed the training data to my model\n",
        "\n",
        "# evaluation function on training data\n",
        "\n",
        "# score it against global data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Input Preprocessing\n",
        "We have a dataset with 3400~ images.  \n",
        "We first downsize the images using Pillow.\n",
        "\n",
        "(Todo: Add python code related to input preprocessing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ptccM9p5hUj3"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Training Method\n",
        "\n",
        "We are going to use a class to represent perceptrons. With some helper functions below.\n",
        "\n",
        "Our approach will be to initialise all the perceptrons/neurons for our Neural Network.\n",
        "\n",
        "- We'll then apply backpropagation using gradient descent.\n",
        "\n",
        "(We won't use any fancy types of Neural Networks like CNN yet which may be better for image classification models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fgrqhaZrMHHj"
      },
      "outputs": [],
      "source": [
        "### Function to evaluate performance\n",
        "def calc_squared_error(y_hat, y):\n",
        "  return (y_hat-y)**2\n",
        "\n",
        "def dumb_evalutor(y_hat, y):\n",
        "  count = 0\n",
        "  for i in range(y_hat):\n",
        "    if y_hat[i] == y[i]:\n",
        "      count +=1\n",
        "  return count / len(y_hat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9GZXFHh5VMtT"
      },
      "outputs": [],
      "source": [
        "class Perceptron:\n",
        "    def __init__(self, weights=1, inputs=1): # TODO: Fixup - I don't think these are ints\n",
        "        self.weights = weights\n",
        "        self.inputs = inputs\n",
        "    def think(self):\n",
        "        total = sum([self.weight*self.input for self.weight, self.input in zip(self.weights, self.inputs)])\n",
        "        return apply_sigmoid_function(total)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjyr1H0uPJix",
        "outputId": "aa4f5a54-b50a-4411-923d-77e0d927ab94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "### Coinflip model\n",
        "\n",
        "# Declare number of hidden layers\n",
        "hidden_layers = 2\n",
        "# Declare number of perceptions per layer\n",
        "### Play around with this number - does having less than output matter?\n",
        "perceptrons_per_layer = 100\n",
        "\n",
        "### Helper initialisation functions\n",
        "def initialise_perceptron_layers():\n",
        "    perceptron_array_2d = []\n",
        "    for i in range(hidden_layers):\n",
        "        perceptron_array = []\n",
        "        for j in range(perceptrons_per_layer):\n",
        "            perceptron_array.append(Perceptron())\n",
        "        perceptron_array_2d.append(perceptron_array)\n",
        "    return perceptron_array_2d\n",
        "\n",
        "def character_classifier_model(df_x, y):\n",
        "    perceptron_array = initialise_perceptron_layers()\n",
        "    return perceptron_array\n",
        "\n",
        "### Helper visualisation functions\n",
        "def print_all_weights(perceptron_array_2d):\n",
        "    for perceptron_array in perceptron_array_2d:\n",
        "        list_of_weights = list(map(lambda x: x.weights, perceptron_array))\n",
        "        print(list_of_weights)\n",
        "\n",
        "### Helper math functions\n",
        "def apply_sigmoid_function(x):\n",
        "  return 1 / (1 + math.exp(-x))\n",
        "\n",
        "print_all_weights(character_classifier_model(1, 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Pending Questions\n",
        "\n",
        "- Q: Does a perceptron have just 1 or many weights? Is it a weight per synapse/per input? How do we represent this in OOP?\n",
        "- Q: Does the sigmoid function get applied to each perception's weight? Or how does it get activated? What is the input (x) for the sigmoid function?\n",
        "  - A: Each neuron's output is processed by the sigmoid function first, so that every neuron's output becomes 0 < output` < 1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
